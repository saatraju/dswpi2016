{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question\n",
    "#1. Word Count\n",
    "\n",
    "#(1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "#(2) Plot a table of the top 30 words with their counts \n",
    "\n",
    "#2. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "#(1) plot a table of the top 10 hashtags, \n",
    "#(2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing Data from File - condolence.json\n",
      "Analysing Data from File - R_I_P.json\n",
      "Analysing Data from File - RIP.json\n",
      "Analysing Data from File - restInPeace.json\n",
      "Total Tweet Count : 360011\n",
      "***** PRINTING TOP 30 WORD COUNT *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condolence</td>\n",
       "      <td>79478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prayers</td>\n",
       "      <td>13350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allah</td>\n",
       "      <td>13200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hang.</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongly</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>condemn</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>injured</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>people.</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>culprits</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>martyrs</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gi…</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>book</td>\n",
       "      <td>11550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lost</td>\n",
       "      <td>7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hav</td>\n",
       "      <td>6470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>po..u</td>\n",
       "      <td>6320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aldubnation</td>\n",
       "      <td>6320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pemily</td>\n",
       "      <td>6320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apart</td>\n",
       "      <td>6320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>family</td>\n",
       "      <td>5448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>memory</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mark</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>terry</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sa</td>\n",
       "      <td>4232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sir</td>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>books</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brandywell</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>po</td>\n",
       "      <td>3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ng</td>\n",
       "      <td>3190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>farren</td>\n",
       "      <td>3150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Count\n",
       "0    condolence  79478\n",
       "1       prayers  13350\n",
       "2         allah  13200\n",
       "3         hang.  12900\n",
       "4      strongly  12900\n",
       "5       condemn  12900\n",
       "6       injured  12900\n",
       "7       people.  12900\n",
       "8      culprits  12900\n",
       "9       martyrs  12900\n",
       "10          gi…  12900\n",
       "11         book  11550\n",
       "12         lost   7970\n",
       "13          hav   6470\n",
       "14        po..u   6320\n",
       "15  aldubnation   6320\n",
       "16       pemily   6320\n",
       "17        apart   6320\n",
       "18       family   5448\n",
       "19       memory   4500\n",
       "20         mark   4500\n",
       "21        terry   4500\n",
       "22           sa   4232\n",
       "23          sir   4050\n",
       "24        books   3750\n",
       "25   brandywell   3750\n",
       "26     tomorrow   3600\n",
       "27           po   3230\n",
       "28           ng   3190\n",
       "29       farren   3150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** PRINTING TOP 10 HASHTAG COUNT *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quetta</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuettaBlast</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDUBBoojieWonderLand</td>\n",
       "      <td>9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MarkFarren</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALDUBPangalawangPagsubok</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saudi</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shia</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TerryWogan</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>auspol</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABSCBNZEROINTEGRITY</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word  Count\n",
       "0                    Quetta  12900\n",
       "1               QuettaBlast  12900\n",
       "2     ALDUBBoojieWonderLand   9322\n",
       "3                MarkFarren   3000\n",
       "4  ALDUBPangalawangPagsubok   2850\n",
       "5                     Saudi   2204\n",
       "6                      Shia   2204\n",
       "7                TerryWogan    900\n",
       "8                    auspol    900\n",
       "9       ABSCBNZEROINTEGRITY    750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** PRINTING TOP 10 SCREEN NAMES COUNT *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TanzeelSHK</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me_gicana28</td>\n",
       "      <td>6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>derrycityfc</td>\n",
       "      <td>6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aldenrichards02</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mainedcm</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abunass3r</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MamuStefie2325</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EatBulaga</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALDUBabaji</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RajivPratapRudy</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  Count\n",
       "0       TanzeelSHK  12900\n",
       "1      me_gicana28   6636\n",
       "2      derrycityfc   6450\n",
       "3  aldenrichards02   2606\n",
       "4         mainedcm   2606\n",
       "5        Abunass3r   2204\n",
       "6   MamuStefie2325   1650\n",
       "7        EatBulaga   1240\n",
       "8       ALDUBabaji   1200\n",
       "9  RajivPratapRudy   1200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "pd.set_option('display.mpl_style', 'default') #Pretty print graph\n",
    "\n",
    "#start pre process_tweet  \n",
    "def preprocesstweet(tweet):        \n",
    "    # process the tweets\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet\n",
    "\n",
    "#start getStopWordList\n",
    "def getStopWordList(stopWordListFileName):\n",
    "    #Stop word list source : \n",
    "    #https://github.com/ravikiranj/twitter-sentiment-analyzer/blob/master/data/feature_list/stopwords.txt        \n",
    "    #read the stopwords file and build a list\n",
    "    stopWords = []\n",
    "    stopWords.append('url')        \n",
    "\n",
    "    fp = open(stopWordListFileName, 'r')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        word = line.strip()\n",
    "        stopWords.append(word)\n",
    "        line = fp.readline()\n",
    "    fp.close()\n",
    "    return stopWords\n",
    "\n",
    "#Function to convert JSON data to panda Datasets\n",
    "def jsonto_PandaDataFrame(tweets):\n",
    "    import pandas as pd\n",
    "    #Create a instance of Panda Dataframe\n",
    "    DataSet = pd.DataFrame()    \n",
    "    #print tweets\n",
    "    for item in tweets:\n",
    "        DataSet['word'] = [l[0] for l in tweets]\n",
    "        DataSet['Count'] = [l[1] for l in tweets]\n",
    "    return DataSet\n",
    "\n",
    "def print_frequency_count(item_list):    \n",
    "    c = Counter(item_list)\n",
    "    result = c.most_common()[:500]\n",
    "    #DataSet = jsonto_PandaDataFrame(result)\n",
    "    return result\n",
    "\n",
    "def get_word_frequency(tweets_data):\n",
    "    #Get the words filtered with stop words and process the frequency.\n",
    "    stopWords = getStopWordList('StopWordList.txt')\n",
    "    status_texts = [ status['text'] \n",
    "                    for status in tweets_data ]\n",
    "\n",
    "    screen_names = [ user_mention['screen_name']\n",
    "                    for status in tweets_data\n",
    "                        for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "    hashtags = [ hashtag['text'] \n",
    "             for status in tweets_data\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "    # Compute a collection of all words from all tweets\n",
    "    words = [ w.lower()\n",
    "             for t in status_texts                  \n",
    "              for w in preprocesstweet(t).split() if not w.startswith(('#', '@')) if w.lower() not in stopWords ]\n",
    "\n",
    "    return words,hashtags,screen_names\n",
    "\n",
    "\n",
    "def plot_graph(tzs):\n",
    "    # Create a bar-graph figure of the specified size\n",
    "    plt.rcParams['figure.figsize'] = (15, 5)\n",
    "    # Plot the Time Zone data as a bar-graph\n",
    "    tzs.plot(kind='bar')\n",
    "    # Assign labels and title to the graph to make it more presentable\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Top 10 retweets')\n",
    "    \n",
    "fls = ['condolence.json','R_I_P.json','RIP.json','restInPeace.json']\n",
    "RT_tweets = []\n",
    "total_tweets = 0\n",
    "total_words,total_ht,total_sn = [],[],[]\n",
    "for f in fls: \n",
    "    tweets_data = []\n",
    "    print \"Analysing Data from File - \" + f\n",
    "    tweets_data_path = f #'condolence.json'    \n",
    "    tweets_file = open(tweets_data_path, \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)        \n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "    total_tweets += len(tweets_data)\n",
    "    words,ht,sn = get_word_frequency(tweets_data)\n",
    "    w_result = print_frequency_count(words)\n",
    "    ht_result = print_frequency_count(ht)\n",
    "    sn_result = print_frequency_count(sn)    \n",
    "    \n",
    "    total_words += w_result\n",
    "    total_ht += ht_result\n",
    "    total_sn += sn_result\n",
    "\n",
    "print \"Total Tweet Count : \"+str(total_tweets)\n",
    "\n",
    "print \"***** PRINTING TOP 30 WORD COUNT *****\"\n",
    "DataSet = jsonto_PandaDataFrame(total_words)\n",
    "display(DataSet.head(30))\n",
    "\n",
    "print \"***** PRINTING TOP 10 HASHTAG COUNT *****\"\n",
    "DataSet = jsonto_PandaDataFrame(total_ht)\n",
    "display(DataSet.head(10))\n",
    "\n",
    "print \"***** PRINTING TOP 10 SCREEN NAMES COUNT *****\"\n",
    "DataSet = jsonto_PandaDataFrame(total_sn)\n",
    "display(DataSet.head(10))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
