{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import jsonpickle\n",
    "import os\n",
    "from tweepy import OAuthHandler\n",
    "import tweepy\n",
    "import time\n",
    "import io\n",
    "def oauth_me():    \n",
    "    CONSUMER_KEY = 'PzE1asPMN71QRQqROIu9di2kJ'\n",
    "    CONSUMER_SECRET ='IZuFT9vW1Uff3vz40pWTwJGF2MhtXl61VqXFLPBAuEKEo1DFrr'\n",
    "    OAUTH_TOKEN = '4864989053-la2b03uVgembzZWMTf7HoPu8Sqg6GGitQ2nwfG1'\n",
    "    OAUTH_TOKEN_SECRET = 'ovBF3RsMQdB7abCZMPXtbS8VR9rb2HJ83ghw2kWkfacuZ'\n",
    "\n",
    "    \n",
    "    #OAuth with tweepy wrappers.\n",
    "    auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "    \n",
    "    # Construct the API instance\n",
    "    api = tweepy.API(auth) # wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    print api\n",
    "    return api\n",
    "\n",
    "\n",
    "searchQuery = 'RIP'  # \n",
    "maxTweets =15000# \n",
    "tweetlimit = 100  # \n",
    "fName = 'RIP.json' # \n",
    "sinceId = \"2015-09-01\"\n",
    "untiL = \"2016-09-07\"\n",
    "\n",
    "\n",
    "def write_to_json(new_tweets, fName):\n",
    "    with open(fName, 'a') as datafile:\n",
    "        for tweet in new_tweets:\n",
    "            datafile.write(jsonpickle.encode(tweet._json, unpicklable=False) + '\\n')\n",
    "\n",
    "fetched_tweetCount=0\n",
    "def search_tweet():\n",
    "    api = oauth_me()\n",
    "    switch = 0\n",
    "    while switch < 4:\n",
    "        num = 0\n",
    "        if switch == 0:\n",
    "            searchQuery = 'RIP'\n",
    "            fName = 'RIP.json'\n",
    "        elif switch == 1:\n",
    "            searchQuery = 'R.I.P'\n",
    "            fName = 'R_I_P.json'\n",
    "        elif switch == 2:\n",
    "            searchQuery = 'rest in peace'\n",
    "            fName = 'restInPeace.json'\n",
    "        elif switch == 3:\n",
    "            searchQuery = 'condolence'\n",
    "            fName = 'condolence.json'\n",
    "        switch += 1    \n",
    "        while num < 6:\n",
    "            fetched_tweetCount = 0\n",
    "            if num == 0:\n",
    "                sinceId = \"2016-02-01\"\n",
    "                untiL = \"2016-02-02\"\n",
    "            elif num == 1:\n",
    "                sinceId = \"2016-02-02\"\n",
    "                untiL = \"2016-02-03\"\n",
    "            elif num == 2:\n",
    "                sinceId = \"2016-02-03\"\n",
    "                untiL = \"2016-02-04\"\n",
    "            elif num == 3:\n",
    "                sinceId = \"2016-02-04\"\n",
    "                untiL = \"2016-02-05\"\n",
    "            elif num == 4:\n",
    "                sinceId = \"2016-02-05\"\n",
    "                untiL = \"2016-02-06\"\n",
    "            elif num == 5:\n",
    "                sinceId = \"2016-02-06\"\n",
    "                untiL = \"2016-02-07\"\n",
    "                \n",
    "            print \"Start Date: {0}\".format(sinceId)\n",
    "            print \"End Date: {0}\".format(untiL)\n",
    "            while fetched_tweetCount < maxTweets:\n",
    "                try:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetlimit, since=sinceId, until = untiL)\n",
    "                    if not new_tweets:\n",
    "                        print \"No more tweets found\" \n",
    "                        break\n",
    "                    write_to_json(new_tweets, fName)\n",
    "                    fetched_tweetCount += len(new_tweets)\n",
    "                    print \"fetched_tweetCount : {0}\".format(fetched_tweetCount)\n",
    "                    max_id = new_tweets[-1].id\n",
    "                except:\n",
    "                    time.sleep(15*60)\n",
    "                    print 'We got a timeout ... Sleeping for 15 minutes'\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetlimit, since=sinceId, until = untiL)\n",
    "                    if not new_tweets:\n",
    "                        print \"No more tweets found\" \n",
    "                        break\n",
    "                    write_to_json(new_tweets, fName)\n",
    "                    fetched_tweetCount += len(new_tweets)\n",
    "                    print \"fetched_tweetCount : {0}\".format(fetched_tweetCount)\n",
    "                    max_id = new_tweets[-1].id \n",
    "            num += 1\n",
    "\n",
    "\n",
    "search_tweet()\n",
    "print (\"Total tweets {0}\".format(fetched_tweetCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
