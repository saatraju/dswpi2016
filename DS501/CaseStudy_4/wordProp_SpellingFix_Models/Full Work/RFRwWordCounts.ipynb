{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 4 :  Data Science Shark Tank:  Pitch Your Ideas\n",
    "\n",
    "** Due Date: April 27, 6pm**\n",
    "<img src=\"https://cp.inkrefuge.com/images%5Cpressreleases/shark%20tank_large.jpg\" width=\"400px\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous 3 case studies,  your team has now equipped with all the three powerful skills of data science: Hacking skill, Business skill and Math skill. In this project, your team is going to make use of these skills to come up with an idea of a new business/startup based upon data science technology. Your goal is to design a better service/solution on any data you like, develop a prototype/demo and prepare a pitch for your idea.\n",
    "* Your team needs to decide which business problem is important for the market you are joining in (for example, social media market, housing market, search market, etc.).\n",
    "* Then design a data science approach to improve one of the current services or design a new service on any data that you choose.\n",
    "* The solution should include all the three components of data science: 1) the business part to analyze the potential impact of your new/improved service, why the idea can make money, how much are you evaluating the company; How are you planing to persuade the sharks to invest in your business; 2) the mathematical part to formulate the problem and develop math solution; 3) the programming part to collect the data, implement the math solution, and develop the prototype/demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background about Elevator Pitch (90 seconds) and Shark Tank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"mrSmaCo29U4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"xIq8Sg59UdY\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two videos on storytelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://video.wpi.edu/Watch/g2T4NjBn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://video.wpi.edu/Watch/q2A6Dbg3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Optional Readings:** \n",
    "* LinkedIn API: https://developer.linkedin.com/docs/rest-api\n",
    "* Zillow API: https://pypi.python.org/pypi/pyzillow\n",
    "* Google Map API: https://developers.google.com/api-client-library/python/apis/mapsengine/v1?hl=en\n",
    "* More APIs: https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition\n",
    "\n",
    "\n",
    "** Python libraries you may want to use:**\n",
    "* Scikit-learn (http://scikit-learn.org): machine learning tools in Python.\n",
    "\n",
    "** Data sources:**\n",
    "* UCI Machine Learning Repository: http://archive.ics.uci.edu/ml/ \n",
    "* Statlib datasets: http://lib.stat.cmu.edu/\n",
    "* Kaggel: www.kaggle.com \n",
    "* Open Gov. Data: www.data.gov, www.data.gov.uk, www.data.gov.fr, http://opengovernmentdata.org/data/catalogues/   \n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: the Business Part (20 points)\n",
    " As a group, learn about the data science related business and research about the current markets: such as search, social media, advertisement, recommendation and so on.\n",
    "Pick one of the markets for further consideration, and design a new service  which you believe to be important in the market. \n",
    "Define precisely in the report and briefly in the cells below, what is the business problem that your team wants to solve.\n",
    "Why the problem is important to solve? \n",
    "Why you believe you could make a big difference with data science technology.\n",
    "How are you planing to persuade the investors to buy in your idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please describe here *briefly*  (please edit this cell)**\n",
    "\n",
    "1) Your business problem to solve:\n",
    "\n",
    "\n",
    "\n",
    "2) Why the problem is important to solve? \n",
    "\n",
    "\n",
    "3) What is your idea to solve the problem? \n",
    "\n",
    "\n",
    "4) What differences you could make with your data science approach?\n",
    "\n",
    "\n",
    "5) Why do you believe the idea deserves the investment of the \"sharks\"?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: The Math Part (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the business problem as a math problem and design a math solution to the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert your answers here**\n",
    "\n",
    "\n",
    "1) Problem formulation in Math:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2) Math Solution:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3) Implementation of the Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "df_train = pd.read_csv('C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\CaseStudy4\\\\input\\\\train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\CaseStudy4\\\\input\\\\test.csv', encoding=\"ISO-8859-1\")\n",
    "# df_attr = pd.read_csv('../input/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\CaseStudy4\\\\input\\\\product_descriptions.csv')\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "#df_test = df_all.iloc[num_train:]\n",
    "#id_test = df_test['id']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "\n",
    "toSplitTrain, finaltest = train_test_split(df_train, test_size = 0.25)\n",
    "df_trainsplit, df_test = train_test_split(toSplitTrain, test_size = 0.25)\n",
    "\n",
    "\n",
    "y_train = df_trainsplit['relevance'].values\n",
    "X_train = df_trainsplit.drop(['id','relevance'],axis=1).values\n",
    "y_actual = df_test['relevance'].values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488845073121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_pred))\n",
    "print rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48403497591\n"
     ]
    }
   ],
   "source": [
    "y_actual_final = finaltest['relevance'].values\n",
    "X_test_final = finaltest.drop(['id','relevance'],axis=1).values\n",
    "y_pred_final = clf.predict(X_test_final)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual_final, y_pred_final))\n",
    "print rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: The Hacking Part  (20 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Collection\n",
    "* Implement a small Demo/Prototype/experiment result figures for the \"product\" of your data science company. You could use this demo during the Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df_train = pd.read_csv('C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\CaseStudy4\\\\input\\\\train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\CaseStudy4\\\\input\\\\product_descriptions.csv')\n",
    "df_merge = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "toSplitTrain, finaltest = train_test_split(df_merge, test_size = 0.25)\n",
    "df_all, df_test = train_test_split(toSplitTrain, test_size = 0.25)\n",
    "\n",
    "\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[df_all.shape[0]]\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lawn_mower\n",
      "mower\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "def synset(word):\n",
    "    return wn.synsets(word)\n",
    "\n",
    "syns = wordnet.synsets('mower')\n",
    "for s in syns:\n",
    "    for a in s.lemmas():\n",
    "        print a._name\n",
    "    \n",
    "\n",
    "#[l.name for s in syns for l in s.lemmas]\n",
    "#[s.lemmas[0].name for s in syns]\n",
    "#[l.name for s in syns for l in s.lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 50\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "colors = np.random.rand(N)\n",
    "area = np.pi * (15 * np.random.rand(N))**2  # 0 to 15 point radiuses\n",
    "\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "### Problem 4: Prepare a 90 second Pitch and *present* it in the class (20 points)\n",
    "\n",
    "* Prepare the slide(s) for the Pitch (10 points)\n",
    "* Present it in the class (10 points).\n",
    "\n",
    "*Advice:  It should really only be one or two slides, but a really good one or two slides!  Also, it is ok to select one person on the team to give the 90 second pitch (though a very organized multi-person 90 second pitch can be very impressive!) *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: communicate the results (20 points)\n",
    "\n",
    "(1) (5 points) What is your business proposition?\n",
    "\n",
    "(2) (5 points) Why this topic is interesting or important to you? (Motivations)\n",
    "\n",
    "(3) (5 points) How did you analyse the data?\n",
    "\n",
    "(4) (5 points) How does your analysis support your business proposition?\n",
    "(please include figures or tables in the report, but no source code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slides (for 10 minutes of presentation) (20 points)\n",
    "\n",
    "\n",
    "1. (5 points) Motivation about the data collection, why the topic is interesting to you. \n",
    "\n",
    "2. (10 points) Communicating Results (figure/table)\n",
    "\n",
    "3. (5 points) Story telling (How all the parts (data, analysis, result) fit together as a story?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: **NOTE, for this Case Study you need to prepare two (2) PPT files!**  One for the 90 second Pitch and one for a normal 10 minute presentation.\n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "\n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "*Please compress all the files into a single zipped file.*\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Send an email to rcpaffenroth@wpi.edu with the subject: \"[DS501] Case study 4\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
